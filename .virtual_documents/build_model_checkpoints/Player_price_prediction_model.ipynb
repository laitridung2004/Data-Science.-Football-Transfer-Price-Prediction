from google.colab import drive
drive.mount('/content/drive')


import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt


# Đọc dữ liệu từ file CSV
file_path = '/content/drive/MyDrive/train_standard.csv'  # Thay đổi đường dẫn nếu cần
df = pd.read_csv(file_path)

# Cấu hình Pandas để hiển thị nhiều dòng và cột
pd.set_option('display.max_columns', None)  # Hiển thị tất cả các cột
pd.set_option('display.max_rows', 10)       # Hiển thị tối đa 10 dòng (bạn có thể thay đổi tùy theo nhu cầu)

# Hiển thị bảng
df.head(100)  # Hiển thị 5 dòng đầu tiên



# Giả sử df là DataFrame chứa dữ liệu của bạn
# df['Price'] là cột chứa giá cầu thủ

# Cấu hình pandas để hiển thị tất cả các dòng
pd.set_option('display.max_rows', None)  # Hiển thị tất cả các dòng
pd.set_option('display.max_columns', None)  # Hiển thị tất cả các cột nếu cần
pd.set_option('display.width', None)  # Tự động điều chỉnh chiều rộng của bảng

# Tính ma trận tương quan
correlation_matrix = df.corr()

# In ra tương quan của các feature với giá cầu thủ
print(correlation_matrix['market_value'].sort_values(ascending=False))

# Hiển thị ma trận tương quan dưới dạng biểu đồ heatmap (nếu cần)
# plt.figure(figsize=(10, 8))
# sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')
# plt.title('Correlation Matrix')
# plt.show()



X_train= df.drop(columns=['market_value'])  # Loại bỏ cột giá cầu thủ
y_train = df['market_value']

file_path_val='/content/drive/MyDrive/valid_standard.csv'
df_val=pd.read_csv(file_path_val)
X_val=df_val.drop(columns=['market_value'])
y_val=df_val['market_value']

file_path_test='/content/drive/MyDrive/test_standard.csv'
df_test=pd.read_csv(file_path_test)
X_test=df_val.drop(columns=['market_value'])
y_test=df_val['market_value']


from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

# Build Linear Regression model
model = LinearRegression()
model.fit(X_train, y_train)



import joblib
import os
# Create the 'checkpoints' directory if it doesn't exist
os.makedirs('/content/drive/MyDrive/checkpoints', exist_ok=True)

#save the model
joblib.dump(model, '/content/drive/MyDrive/checkpoints/linear_regression_model.pkl')
print("Model saved as 'linear_regression_model.pkl'")


model=joblib.load('/content/drive/MyDrive/checkpoints/linear_regression_model.pkl')
y_pred = model.predict(X_test)
mae = mean_absolute_error(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f"Linear Regression- MAE: {mae:.2f}")
print(f"Linear Regression - MSE: {mse:.2f}")
print(f"Linear Regression - R² Score: {r2:.2f}")




bias = 0
non_bias = 0
biased_players = []  # Danh sách để lưu thông tin các cầu thủ bị bias

for sample_index in range(30):  # Chỉ số của cầu thủ trong tập test
    X_sample = X_test.iloc[[sample_index]]  # Dữ liệu của cầu thủ cần dự đoán
    y_real = y_test.iloc[sample_index]  # Giá trị thực tế của cầu thủ

    # Sử dụng meta model để dự đoán
    y_predict = model.predict(X_sample)

    # Kiểm tra bias
    if abs(y_real - y_predict[0]) > 1.5:
        bias += 1
        # Lấy dữ liệu các feature của cầu thủ
        player_features = X_sample.iloc[0].tolist()
        # Thêm giá trị dự đoán và giá trị thực tế vào dữ liệu
        player_features.extend([y_predict[0], y_real])
        biased_players.append(player_features)
    else:
        non_bias += 1

# Kiểm tra nếu có ít nhất một cầu thủ bị bias
if biased_players:
    # Lấy tên các feature từ X_test
    feature_names = X_test.columns.tolist()
    # Thêm tên cột cho giá dự đoán và giá thực tế
    feature_names.extend(['Predicted Price', 'Real Price'])

    # Tạo DataFrame từ danh sách các cầu thủ bị bias
    biased_df = pd.DataFrame(biased_players, columns=feature_names)

    # In DataFrame
    print("Bảng các cầu thủ bị bias (sai số > 1.5):")
    print(biased_df.to_string(index=False))
else:
    print("Không có cầu thủ nào bị bias với sai số > 1.5.")

# In tổng số cầu thủ bị bias và không bị bias
print(f'Tổng số cầu thủ bị bias: {bias}')
print(f'Tổng số cầu thủ không bị bias: {non_bias}')



from sklearn.ensemble import RandomForestRegressor

model_rf = RandomForestRegressor(random_state=42)
model_rf.fit(X_train, y_train)


import joblib

# Lưu mô hình vào file
joblib.dump(model_rf, '/content/drive/MyDrive/checkpoints/random_forest_model.pkl')
print("Model saved as 'random_forest_model.pkl'")



model_rf=joblib.load('/content/drive/MyDrive/checkpoints/random_forest_model.pkl')

y_pred_rf = model_rf.predict(X_test)
mae_rf = mean_absolute_error(y_test, y_pred_rf)
mse_rf = mean_squared_error(y_test, y_pred_rf)
r2_rf = r2_score(y_test, y_pred_rf)

print(f"Random Forest - MAE: {mae_rf:.2f}")
print(f"Random Forest - MSE: {mse_rf:.2f}")
print(f"Random Forest - R² Score: {r2_rf:.2f}")


# === 4. Dự đoán giá của cầu thủ cụ thể ===
bias = 0
non_bias = 0
biased_players = []  # Danh sách để lưu thông tin các cầu thủ bị bias

for sample_index in range(30):  # Chỉ số của cầu thủ trong tập test
    X_sample = X_test.iloc[[sample_index]]  # Dữ liệu của cầu thủ cần dự đoán
    y_real = y_test.iloc[sample_index]  # Giá trị thực tế của cầu thủ

    # Sử dụng meta model để dự đoán
    y_predict = model_rf.predict(X_sample)

    # Kiểm tra bias
    if abs(y_real - y_predict[0]) > 1.5:
        bias += 1
        # Lấy dữ liệu các feature của cầu thủ
        player_features = X_sample.iloc[0].tolist()
        # Thêm giá trị dự đoán và giá trị thực tế vào dữ liệu
        player_features.extend([y_predict[0], y_real])
        biased_players.append(player_features)
    else:
        non_bias += 1

# Kiểm tra nếu có ít nhất một cầu thủ bị bias
if biased_players:
    # Lấy tên các feature từ X_test
    feature_names = X_test.columns.tolist()
    # Thêm tên cột cho giá dự đoán và giá thực tế
    feature_names.extend(['Predicted Price', 'Real Price'])

    # Tạo DataFrame từ danh sách các cầu thủ bị bias
    biased_df = pd.DataFrame(biased_players, columns=feature_names)

    # In DataFrame
    print("Bảng các cầu thủ bị bias (sai số > 1.5):")
    print(biased_df.to_string(index=False))
else:
    print("Không có cầu thủ nào bị bias với sai số > 1.5.")

# In tổng số cầu thủ bị bias và không bị bias
print(f'Tổng số cầu thủ bị bias: {bias}')
print(f'Tổng số cầu thủ không bị bias: {non_bias}')



from xgboost import XGBRegressor

xgb_model = XGBRegressor(n_estimators=200, max_depth=5, learning_rate=0.1, random_state=42)
xgb_model.fit(X_train, y_train)



xgb_model=joblib.load('/content/drive/MyDrive/checkpoints/xgboost_model.pkl')
y_pred_xgb = xgb_model.predict(X_test)
mae_xgb = mean_absolute_error(y_test, y_pred_xgb)
mse_xgb = mean_squared_error(y_test, y_pred_xgb)
r2_xgb = r2_score(y_test, y_pred_xgb)

print(f"XGBoost - MSE: {mse_xgb:.2f}, MAE: {mae_xgb:.2f}, R²: {r2_xgb:.2f}")


import joblib

# Lưu mô hình XGBoost bằng Joblib
joblib.dump(xgb_model, '/content/drive/MyDrive/checkpoints/xgboost_model.pkl')
print("Model saved as 'xgboost_model.pkl'")



# === 4. Dự đoán giá của cầu thủ cụ thể ===
bias = 0
non_bias = 0
biased_players = []  # Danh sách để lưu thông tin các cầu thủ bị bias

for sample_index in range(30):  # Chỉ số của cầu thủ trong tập test
    X_sample = X_test.iloc[[sample_index]]  # Dữ liệu của cầu thủ cần dự đoán
    y_real = y_test.iloc[sample_index]  # Giá trị thực tế của cầu thủ

    # Sử dụng meta model để dự đoán
    y_predict = xgb_model.predict(X_sample)

    # Kiểm tra bias
    if abs(y_real - y_predict[0]) > 1.5:
        bias += 1
        # Lấy dữ liệu các feature của cầu thủ
        player_features = X_sample.iloc[0].tolist()
        # Thêm giá trị dự đoán và giá trị thực tế vào dữ liệu
        player_features.extend([y_predict[0], y_real])
        biased_players.append(player_features)
    else:
        non_bias += 1

# Kiểm tra nếu có ít nhất một cầu thủ bị bias
if biased_players:
    # Lấy tên các feature từ X_test
    feature_names = X_test.columns.tolist()
    # Thêm tên cột cho giá dự đoán và giá thực tế
    feature_names.extend(['Predicted Price', 'Real Price'])

    # Tạo DataFrame từ danh sách các cầu thủ bị bias
    biased_df = pd.DataFrame(biased_players, columns=feature_names)

    # In DataFrame
    print("Bảng các cầu thủ bị bias (sai số > 1.5):")
    print(biased_df.to_string(index=False))
else:
    print("Không có cầu thủ nào bị bias với sai số > 1.5.")

# In tổng số cầu thủ bị bias và không bị bias
print(f'Tổng số cầu thủ bị bias: {bias}')
print(f'Tổng số cầu thủ không bị bias: {non_bias}')



from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.regularizers import l2
from tensorflow.keras.callbacks import ModelCheckpoint
from tensorflow.keras.initializers import GlorotNormal
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error

# Tạo mô hình ANN


model_nn = Sequential([
    Dense(128, activation='relu', input_dim=X_train.shape[1],kernel_initializer=GlorotNormal()),
    Dropout(0.3),
    Dense(64, activation='relu',kernel_initializer=GlorotNormal()),
    Dropout(0.3),
    Dense(32, activation='relu',kernel_initializer=GlorotNormal()),
    Dropout(0.3),
    Dense(1)
])

model_nn.compile(optimizer=Adam(learning_rate=0.00001), loss='mse', metrics=['mae'])
# Tạo thư mục để lưu các checkpoint
checkpoint_dir = '/content/drive/MyDrive/checkpoints/'

# ModelCheckpoint callback để lưu mô hình tốt nhất dựa trên val_loss
checkpoint_callback = ModelCheckpoint(
    filepath=os.path.join(checkpoint_dir, 'nn_model.keras'),
    monitor='val_mae',         # Giám sát val_loss
    mode='min',                 # Tìm giá trị nhỏ nhất của val_loss
    save_best_only=True,        # Lưu mô hình tốt nhất
    verbose=1
)


# Huấn luyện với tập validation có sẵn
model_nn.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=400, batch_size=32,callbacks=[checkpoint_callback])



from tensorflow.keras.models import load_model

model_path = '/content/drive/MyDrive/checkpoints/nn_model.keras'

best_model = load_model(model_path)

# Dự đoán trên tập test
y_pred_best = best_model.predict(X_test)

# Đánh giá mô hình trên tập test
mse_best = mean_squared_error(y_test, y_pred_best)
mae_best = mean_absolute_error(y_test, y_pred_best)
r2_best = r2_score(y_test, y_pred_best)

print(f"Best Model - MSE: {mse_best:.2f}")
print(f"Best Model - MAE: {mae_best:.2f}")
print(f"Best Model - R²: {r2_best:.2f}")



#Lasso regression
from sklearn.linear_model import Lasso

lasso = Lasso(alpha=0.001)
lasso.fit(X_train, y_train)



import joblib

# Lưu mô hình Lasso Regression
joblib.dump(lasso, '/content/drive/MyDrive/checkpoints/lasso_model.pkl')
print("Model saved as 'lasso_model.pkl'")




lasso=joblib.load('/content/drive/MyDrive/checkpoints/lasso_model.pkl')
y_pred_lasso = lasso.predict(X_test)

mse_lasso = mean_squared_error(y_test, y_pred_lasso)
mae_lasso=mean_absolute_error(y_test,y_pred_lasso)
r2_lasso = r2_score(y_test, y_pred_lasso)

print(f"Lasso Regression - MSE: {mse_lasso:.2f},MAE:{mae_lasso:.2f}, R²: {r2_lasso:.2f}")



# Ridge regression
from sklearn.model_selection import  GridSearchCV
from sklearn.linear_model import Ridge

ridge = Ridge()
param_grid = {'alpha': np.logspace(-4, 4, 1000)}  # Tìm trong khoảng 1e-4 đến 1e4
grid_search = GridSearchCV(ridge, param_grid, cv=5, scoring='r2', n_jobs=-1)
grid_search.fit(X_train, y_train)

# 6. Huấn luyện mô hình Ridge Regression với alpha tối ưu
best_alpha = grid_search.best_params_['alpha']
print(f"Best alpha: {best_alpha}")

ridge_best = Ridge(alpha=best_alpha)
ridge_best.fit(X_train, y_train)


# Lưu mô hình Ridge Regression với alpha tối ưu
joblib.dump(ridge_best, '/content/drive/MyDrive/checkpoints/ridge_best_model.pkl')
print("Model saved as 'ridge_best_model.pkl'")



ridge_best=joblib.load('/content/drive/MyDrive/checkpoints/ridge_best_model.pkl')
y_pred = ridge_best.predict(X_test)
# 8. Đánh giá mô hình
mse = mean_squared_error(y_test, y_pred)
mae = mean_absolute_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f"Ridge Regression - MSE: {mse:.2f}")
print(f"Ridge Regression - MAE: {mae:.2f}")
print(f"Ridge Regression - R²: {r2:.2f}")


pip install catboost


from catboost import CatBoostRegressor
from sklearn.metrics import mean_squared_error, r2_score

# Huấn luyện CatBoost
catboost_model = CatBoostRegressor(iterations=500, learning_rate=0.05, depth=7, random_state=42, verbose=0)
catboost_model.fit(X_train, y_train, eval_set=(X_val, y_val), early_stopping_rounds=10)


import joblib

# Lưu mô hình CatBoost bằng Joblib
joblib.dump(catboost_model, '/content/drive/MyDrive/checkpoints/catboost_model.pkl')
print("Model saved as 'catboost_model.pkl'")



catboost_model=joblib.load('/content/drive/MyDrive/checkpoints/catboost_model.pkl')
y_pred_catboost = catboost_model.predict(X_test)
# Đánh giá
mse_catboost = mean_squared_error(y_test, y_pred_catboost)
mae_catboost=mean_absolute_error(y_test,y_pred_catboost)
r2_catboost = r2_score(y_test, y_pred_catboost)
print(f"CatBoost - MSE: {mse_catboost:.2f},MAE: {mae_catboost:.2f}, R²: {r2_catboost:.2f}")



from xgboost import XGBClassifier
from catboost import CatBoostClassifier

# === 1. Tải các mô hình base đã lưu ===
catboost_model = joblib.load('build_model_checkpoints/checkpoints//catboost_model.pkl')
lasso_model = joblib.load('build_model_checkpoints/checkpoints//lasso_model.pkl')
random_forest_model = joblib.load('build_model_checkpoints/checkpoints//random_forest_model.pkl')
ridge_model = joblib.load('build_model_checkpoints/checkpoints//ridge_best_model.pkl')
xgboost_model = joblib.load('build_model_checkpoints/checkpoints//xgboost_model.pkl')
linear_regression_model = joblib.load('build_model_checkpoints/checkpoints//linear_regression_model.pkl')
neural_network_model = load_model('build_model_checkpoints/checkpoints//nn_model.keras')

# === 2. Hàm dự đoán từ các base models ===
def predict_with_models(X):
    predictions = {
        'catboost': catboost_model.predict(X),
        'lasso': lasso_model.predict(X),
        'random_forest': random_forest_model.predict(X),
        'ridge': ridge_model.predict(X),
        'xgboost': xgboost_model.predict(X),
        'linear_regression': linear_regression_model.predict(X),
        'neural_network': neural_network_model.predict(X).flatten()  # Neural network outputs a flattened array
    }
    return predictions

# === 3. Tạo tập meta từ các dự đoán base models ===
def create_meta_dataset(X, y):
    predictions = predict_with_models(X)
    meta_features = pd.DataFrame(predictions)  # Chuyển các dự đoán thành DataFrame
    meta_features['true_target'] = y           # Thêm nhãn thực tế
    return meta_features

# === 4. Huấn luyện meta model ===
# Meta model với XGBoost
def train_meta_model_xgb(X_train, y_train, X_val, y_val):
    meta_train = create_meta_dataset(X_train, y_train)
    meta_val = create_meta_dataset(X_val, y_val)

    # Meta features và nhãn
    X_meta_train = meta_train.drop(columns=['true_target'])
    y_meta_train = np.argmin(np.abs(meta_train.drop(columns=['true_target']).values - meta_train['true_target'].values[:, None]), axis=1)

    # Huấn luyện XGBoost
    meta_model = XGBClassifier(n_estimators=100, max_depth=3, learning_rate=0.1, random_state=42)
    meta_model.fit(X_meta_train, y_meta_train)

    return meta_model

# Meta model với CatBoost
def train_meta_model_catboost(X_train, y_train, X_val, y_val):
    meta_train = create_meta_dataset(X_train, y_train)
    meta_val = create_meta_dataset(X_val, y_val)

    # Meta features và nhãn
    X_meta_train = meta_train.drop(columns=['true_target'])
    y_meta_train = np.argmin(np.abs(meta_train.drop(columns=['true_target']).values - meta_train['true_target'].values[:, None]), axis=1)

    # Huấn luyện CatBoost
    meta_model = CatBoostClassifier(iterations=500, learning_rate=0.05, depth=6, random_state=42, verbose=0)
    meta_model.fit(X_meta_train, y_meta_train)

    return meta_model

# === 5. Hàm dự đoán với meta model ===
def ensemble_predict(X, meta_model):
    base_predictions = predict_with_models(X)
    base_df = pd.DataFrame(base_predictions)

    # Meta model chọn mô hình tốt nhất cho từng sample
    best_model_indices = meta_model.predict(base_df)

    # Chọn dự đoán từ mô hình được chọn
    final_predictions = []
    for i, idx in enumerate(best_model_indices):
        final_predictions.append(base_df.iloc[i, idx])

    return np.array(final_predictions)

# Huấn luyện meta model với XGBoost
meta_model_xgb = train_meta_model_xgb(X_train, y_train, X_val, y_val)

# Huấn luyện meta model với CatBoost
meta_model_catboost = train_meta_model_catboost(X_train, y_train, X_val, y_val)



# Lưu mô hình XGBoost
joblib.dump(meta_model_xgb, '/content/drive/MyDrive/checkpoints/meta_model_xgb.pkl')

# Lưu mô hình CatBoost
joblib.dump(meta_model_catboost, '/content/drive/MyDrive/checkpoints/meta_model_catboost.pkl')



meta_model_xgb=joblib.load('/content/drive/MyDrive/checkpoints/meta_model_xgb.pkl')
y_pred_ensemble_xgb = ensemble_predict(X_test, meta_model_xgb)

# Đánh giá hiệu suất XGB
mse_xgb = mean_squared_error(y_test, y_pred_ensemble_xgb)
mae_xgb = mean_absolute_error(y_test, y_pred_ensemble_xgb)
r2_xgb = r2_score(y_test, y_pred_ensemble_xgb)
print(f"Ensemble Model (XGBoost) - MSE: {mse_xgb:.2f}")
print(f"Ensemble Model (XGBoost) - MAE: {mae_xgb:.2f}")
print(f"Ensemble Model (XGBoost) - R²: {r2_xgb:.2f}")

# #############

meta_model_catboost=joblib.load('/content/drive/MyDrive/checkpoints/meta_model_catboost.pkl')
y_pred_ensemble_catboost = ensemble_predict(X_test, meta_model_catboost)

# Đánh giá hiệu suất
mse_catboost = mean_squared_error(y_test, y_pred_ensemble_catboost)
mae_catboost = mean_absolute_error(y_test, y_pred_ensemble_catboost)
r2_catboost = r2_score(y_test, y_pred_ensemble_catboost)
print(f"Ensemble Model (CatBoost) - MSE: {mse_catboost:.2f}")
print(f"Ensemble Model (CatBoost) - MAE: {mae_catboost:.2f}")
print(f"Ensemble Model (CatBoost) - R²: {r2_catboost:.2f}")




def test_model_bias(X_test, y_test, meta_model_xgb, meta_model_catboost, threshold=1.5, num_samples=30):
    bias_xgb = 0
    bias_catboost = 0
    non_bias_xgb = 0
    non_bias_catboost = 0

    biased_players_xgb = []  # Danh sách các cầu thủ bị bias với meta_model_xgb
    biased_players_catboost = []  # Danh sách các cầu thủ bị bias với meta_model_catboost

    # Lặp qua các mẫu cầu thủ trong tập test
    for sample_index in range(num_samples):
        X_sample = X_test.iloc[[sample_index]]  # Lấy dữ liệu cầu thủ cần dự đoán
        y_real = y_test.iloc[sample_index]  # Lấy giá trị thực tế của cầu thủ

        # Dự đoán với meta model XGBoost
        y_predict_xgb = ensemble_predict(X_test.iloc[sample_index:sample_index+1], meta_model_xgb)

        # Kiểm tra bias với meta model XGBoost
        if abs(y_real - y_predict_xgb[0]) > threshold:
            bias_xgb += 1
            player_features = X_sample.iloc[0].tolist()  # Lấy đặc trưng cầu thủ
            player_features.extend([y_predict_xgb[0], y_real])  # Thêm giá trị dự đoán và giá trị thực tế
            biased_players_xgb.append(player_features)
        else:
            non_bias_xgb += 1

        # Dự đoán với meta model CatBoost
        y_predict_catboost = ensemble_predict(X_test.iloc[sample_index:sample_index+1], meta_model_catboost)

        # Kiểm tra bias với meta model CatBoost
        if abs(y_real - y_predict_catboost[0][0]) > threshold:
            bias_catboost += 1
            player_features = X_sample.iloc[0].tolist()  # Lấy đặc trưng cầu thủ
            player_features.extend([y_predict_catboost[0][0], y_real])  # Thêm giá trị dự đoán và giá trị thực tế
            biased_players_catboost.append(player_features)
        else:
            non_bias_catboost += 1

    # Hiển thị kết quả cho XGBoost
    print("\n--- Kết quả với mô hình XGBoost ---")
    if biased_players_xgb:
        feature_names = X_test.columns.tolist()
        feature_names.extend(['Predicted Price', 'Real Price'])
        biased_df_xgb = pd.DataFrame(biased_players_xgb, columns=feature_names)
        print(f"Bảng các cầu thủ bị bias với XGBoost (sai số > {threshold}):")
        print(biased_df_xgb.to_string(index=False))
    else:
        print(f"Không có cầu thủ nào bị bias với XGBoost (sai số > {threshold}).")
    print(f"Tổng số cầu thủ bị bias với XGBoost: {bias_xgb}")
    print(f"Tổng số cầu thủ không bị bias với XGBoost: {non_bias_xgb}")

    # Hiển thị kết quả cho CatBoost
    print("\n--- Kết quả với mô hình CatBoost ---")
    if biased_players_catboost:
        biased_df_catboost = pd.DataFrame(biased_players_catboost, columns=feature_names)
        print(f"Bảng các cầu thủ bị bias với CatBoost (sai số > {threshold}):")
        print(biased_df_catboost.to_string(index=False))
    else:
        print(f"Không có cầu thủ nào bị bias với CatBoost (sai số > {threshold}).")
    print(f"Tổng số cầu thủ bị bias với CatBoost: {bias_catboost}")
    print(f"Tổng số cầu thủ không bị bias với CatBoost: {non_bias_catboost}")
# Test mô hình với ngưỡng bias là 1.5 và kiểm tra 30 cầu thủ
test_model_bias(X_test, y_test, meta_model_xgb, meta_model_catboost, threshold=1.5, num_samples=30)

